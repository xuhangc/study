{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Gradient Boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "tr_features = pd.read_csv('./train_features.csv')\n",
    "tr_labels = pd.read_csv('./train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![GB](../../img/gb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BEST PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n\n0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n0.811 (+/-0.117) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n0.811 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n0.83 (+/-0.074) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n0.841 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n0.82 (+/-0.051) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n0.818 (+/-0.043) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n0.826 (+/-0.047) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n0.818 (+/-0.053) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n0.817 (+/-0.025) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n0.803 (+/-0.032) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n0.803 (+/-0.059) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n0.803 (+/-0.037) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n0.786 (+/-0.044) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n0.796 (+/-0.115) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n0.815 (+/-0.119) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n0.818 (+/-0.111) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n0.828 (+/-0.092) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n0.813 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n0.839 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n0.828 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n0.809 (+/-0.04) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n0.817 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n0.818 (+/-0.019) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n0.805 (+/-0.029) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n0.796 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n0.817 (+/-0.056) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n0.796 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n0.8 (+/-0.019) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n0.792 (+/-0.03) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n0.798 (+/-0.048) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n0.79 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n0.783 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n0.792 (+/-0.032) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n0.818 (+/-0.099) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n0.832 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n0.826 (+/-0.077) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n0.822 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n0.82 (+/-0.061) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n0.798 (+/-0.02) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n0.792 (+/-0.033) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n0.79 (+/-0.028) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n0.801 (+/-0.025) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n0.787 (+/-0.048) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n0.796 (+/-0.038) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n0.794 (+/-0.029) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n0.787 (+/-0.035) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n0.798 (+/-0.046) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n0.798 (+/-0.052) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n0.8 (+/-0.035) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n0.773 (+/-0.058) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n0.798 (+/-0.052) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n0.792 (+/-0.05) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n0.794 (+/-0.033) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n0.414 (+/-0.258) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n0.412 (+/-0.181) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n0.438 (+/-0.251) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n0.414 (+/-0.264) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n0.631 (+/-0.208) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n0.624 (+/-0.16) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n0.599 (+/-0.187) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n0.577 (+/-0.192) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n0.704 (+/-0.121) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n0.672 (+/-0.129) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n0.687 (+/-0.099) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n0.693 (+/-0.101) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n0.354 (+/-0.191) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n0.357 (+/-0.192) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n0.357 (+/-0.186) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n0.365 (+/-0.194) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n0.586 (+/-0.099) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n0.564 (+/-0.107) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n0.571 (+/-0.113) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n0.58 (+/-0.1) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n0.676 (+/-0.091) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n0.652 (+/-0.075) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n0.691 (+/-0.072) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n0.685 (+/-0.085) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./GB_model.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, './GB_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}