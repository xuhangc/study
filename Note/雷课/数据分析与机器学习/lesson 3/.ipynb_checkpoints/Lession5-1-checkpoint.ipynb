{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <center>网络数据获取——基本操作</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 课程内容\n",
    "\n",
    "* 1.爬取数据\n",
    "* 2.网络请求——requests\n",
    "* 3.文本解析——BeautifulSoup与re\n",
    "* 4.动态网页——selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.爬取数据\n",
    "\n",
    "从网站 https://www.liaoxuefeng.com/wiki/1016959663602400/1016959735620448 爬取图片，并保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#第1步：引入所需包\n",
    "import requests\n",
    "#第2步：构造URL\n",
    "url = 'https://static.liaoxuefeng.com/files/attachments/921215396004384/0'\n",
    "#第3步：请求URL\n",
    "r = requests.get(url)\n",
    "#第4步：解析数据\n",
    "with open(\"python.png\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.网络请求\n",
    "* Python 提供了很多模块来支持 HTTP 协议的网络编程，urllib、urllib2、urllib3、httplib、httplib2，都是和 HTTP 相关的模块，看名字觉得很反人类，更糟糕的是这些模块在 Python2 与 Python3 中有很大的差异，如果业务代码要同时兼容 2 和 3，写起来会让人崩溃。\n",
    "\n",
    "* 幸运地是，繁荣的 Python 社区给开发者带来了一个非常惊艳的 HTTP 库 requests，一个真正给人用的HTTP库。它是 GitHUb 关注数最多的 Python 项目之一，requests 的作者是 Kenneth Reitz 大神。\n",
    "\n",
    "* requests 实现了 HTTP 协议中绝大部分功能，它提供的功能包括 Keep-Alive、连接池、Cookie持久化、内容自动解压、HTTP代理、SSL认证、连接超时、Session等很多特性，最重要的是它同时兼容 python2 和 python3。\n",
    "\n",
    "* 让 HTTP 服务人类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 发送请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取response对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET 请求\n",
    "response = requests.get(\"https://baidu.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请求返回 Response 对象，Response 对象是 对 HTTP 协议中服务端返回给浏览器的响应数据的封装，响应的中的主要元素包括：状态码、原因短语、响应首部、响应体等等，这些属性都封装在Response 对象中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### response对象的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http请求的返回状态，200表示连接成功，400代表失败\n",
    "response.status_code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从HTTP header中猜测的响应内容编码方式，若header中不存在charset,则默认为'ISO-8859-1'\n",
    "response.encoding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从内容中分析出的响应内容编码方式（备选编码方式）\n",
    "response.apparent_encoding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 原因短语\n",
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.headers['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 响应首部\n",
    "for name,value in response.headers.items():\n",
    "    print(\"%s:%s\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HTTP响应内容的字符串形式 即，url对应的页面内容\n",
    "response.text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http响应内容的二进制形式\n",
    "response.content  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requests 除了支持 GET 请求外，还支持 HTTP 规范中的其它所有方法，包括 POST、PUT、DELTET、HEADT、OPTIONS方法。\n",
    "\n",
    "|方法| 说明|\n",
    "| ------------- |:-------------:|\n",
    "|requests.request() |构造一个请求，支撑以下各方法的基础方法|\n",
    "|requests.get() |获取HTML网页的主要方法，对应于HTTP的GET|\n",
    "|requests.head() |获取HTML网页头信息的方法，对应于HTTP的HEAD|\n",
    "|requests.post() |向HTML网页提交POST请求的方法，对应于HTTP的POST|\n",
    "|requests.put() |向HTML网页提交PUT请求的方法，对应于HTTP的PUT|\n",
    "|requests.patch() |向HTML网页提交局部修改请求，对应于HTTP的PATCH|\n",
    "|requests.delete() |向HTML页面提交删除请求，对应于HTTP的DELETE|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.post('http://httpbin.org/post', data = {'key':'value'})\n",
    "response = requests.put('http://httpbin.org/put', data = {'key':'value'})\n",
    "response = requests.delete('http://httpbin.org/delete')\n",
    "response = requests.head('http://httpbin.org/get')\n",
    "response = requests.options('http://httpbin.org/get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.post('http://baidu.com', data = {'key':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requests库的异常\n",
    "\n",
    "| 异常        | 说明           |\n",
    "| ------------- |:-------------:|\n",
    "| requests.ConnectionError      | 网络连接错误异常，如DNS查询失败、拒绝连接等 |\n",
    "| requests.HTTPError      | HTTP错误异常      |\n",
    "| requests.URLRequired      | URL缺失异常      |\n",
    "| requests.TooManyRedirects      | 超过最大重定向次数，产生重定向异常      |\n",
    "| requests.ConnectTimeout       | 连接远程服务器超时异常      |\n",
    "| requests.Timeout      | 请求URL超时，产生超时异常      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 网络连接错误异常\n",
    "requests.ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HTTP错误异常\n",
    "requests.HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# URL缺失异常\n",
    "requests.URLRequired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 超过最大重定向次数，产生重定向异常\n",
    "requests.TooManyRedirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 连接远程服务器超时异常\n",
    "requests.ConnectTimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 请求URL超时，产生超时异常\n",
    "requests.Timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建请求查询参数\n",
    "* 很多URL都带有很长一串参数，称这些参数为URL的查询参数，用”?”附加在URL链接后面，多个参数之间用”&”隔开，比如：httpbin.org/get?key=val 。\n",
    "* Requests允许使用 params 关键字参数，以一个字符串字典来提供这些参数。举例来说，如果你想传递 key1=value1 和 key2=value2 到 httpbin.org/get ，那么你可以使用如下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "response = requests.get(\"http://baidu.com\", params=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过打印输出该 URL，你能看到 URL 已被正确编码：\n",
    "print(response.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://httpbin.org/get?key1=value1&key2=value2'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还可以将一个列表作为值传入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = {'key1': 'value1', 'key2': ['value2', 'value3']}\n",
    "\n",
    "response = requests.get('http://httpbin.org/get', params=payload)\n",
    "print(response.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建请求首部 Headers\n",
    "* requests 可以很简单地指定请求首部字段 Headers，比如有时要指定 User-Agent 伪装成浏览器发送请求，以此来蒙骗服务器。直接传递一个字典对象给参数 headers 即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://baidu.com'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(url, headers={'user-agent': 'Mozilla/5.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意: 所有的 header 值必须是 string、bytestring 或者 unicode。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.zhihu.com\")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为访问知乎需要头部信息，这个时候我们在谷歌浏览器里输入chrome://version, 就可以看到用户代理，将用户代理添加到头部信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "response =requests.get(\"https://www.zhihu.com\", headers=headers)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建 POST 请求数据\n",
    "* requests 可以非常灵活地构建 POST 请求需要的数据，如果服务器要求发送的数据是表单数据，则可以指定关键字参数 data，如果要求传递 json 格式字符串参数，则可以使用json关键字参数，参数的值都可以字典的形式传过去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 作为表单数据传输给服务器\n",
    "payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "r = requests.post(\"http://httpbin.org/post\", data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 作为 json 格式的字符串格式传输给服务器\n",
    "import json\n",
    "url = 'http://httpbin.org/post'\n",
    "payload = {'some': 'data'}\n",
    "r = requests.post(url, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 响应内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response中的响应体\n",
    "* HTTP返回的响应消息中很重要的一部分内容是响应体，响应体在 requests 中处理非常灵活，与响应体相关的属性有：content、text、json()。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content 是 byte 类型，适合直接将内容保存到文件系统或者传输到网络中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"https://pic1.zhimg.com/v2-2e92ebadb4a967829dcd7d05908ccab0_b.jpg\")\n",
    "type(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 另存为 test.jpg\n",
    "with open(\"test.jpg\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text 是 str 类型，比如一个普通的 HTML 页面，需要对文本进一步分析时，使用 text。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"https://baidu.com\")\n",
    "type(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用第三方开放平台或者API接口爬取数据时，返回的内容是json格式的数据时，那么可以直接使用json()方法返回一个经过json.loads()处理后的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://api.github.com/events')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在罕见的情况下，你可能想获取来自服务器的原始套接字响应，那么你可以访问 r.raw。 如果你确实想这么干，那请你确保在初始请求中设置了 stream=True。具体你可以这么做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://api.github.com/events')\n",
    "r.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.raw.read(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://api.github.com/events', stream=True)\n",
    "r.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.raw.read(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 响应状态码\n",
    "\n",
    "* 200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', '✓')\n",
    "\n",
    "* 400: ('bad_request', 'bad')\n",
    "\n",
    "* 401: ('unauthorized',)\n",
    "\n",
    "* 403: ('forbidden',)\n",
    "\n",
    "* 404: ('not_found', '-o-')\n",
    "\n",
    "* 500: ('internal_server_error', 'server_error', '/o\\', '✗')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://httpbin.org/get')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为方便引用，Requests还附带了一个内置的状态码查询对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.status_code == requests.codes.ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果发送了一个错误请求(一个 4XX 客户端错误，或者 5XX 服务器错误响应)，我们可以通过 Response.raise_for_status() 来抛出异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_r = requests.get('http://httpbin.org/status/404')\n",
    "bad_r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://httpbin.org')\n",
    "r.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 响应头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用任意大写形式来访问这些响应头字段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.headers.get('content-type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代理设置\n",
    "* 当爬虫频繁地对服务器进行抓取内容时，很容易被服务器屏蔽掉，因此要想继续顺利的进行爬取数据，使用代理是明智的选择。如果你想爬取墙外的数据，同样设置代理可以解决问题，requests 完美支持代理。\n",
    "\n",
    "```py\n",
    "proxies = {\n",
    "  'http': 'http://10.10.1.10:3128',\n",
    "  'https': 'http://10.10.1.10:1080',\n",
    "}\n",
    "\n",
    "requests.get('http://example.org', proxies=proxies)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超时设置\n",
    "* requests 发送请求时，默认请求下线程一直阻塞，直到有响应返回才处理后面的逻辑。如果遇到服务器没有响应的情况时，问题就变得很严重了，它将导致整个应用程序一直处于阻塞状态而没法处理其他请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"http://www.go111ogle.c11om\") # 一直阻塞中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确的方式的是给每个请求显示地指定一个超时时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"http://httpbin.org\", timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session\n",
    "* HTTP协议是一中无状态的协议，为了维持客户端与服务器之间的通信状态，使用 Cookie 技术使之保持双方的通信状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些网页是需要登录才能进行爬虫操作的，而登录的原理就是浏览器首次通过用户名密码登录之后，服务器给客户端发送一个随机的Cookie，下次浏览器请求其它页面时，就把刚才的 cookie 随着请求一起发送给服务器，这样服务器就知道该用户已经是登录用户。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://httpbin.org/cookies'\n",
    "cookies = dict(cookies_are='working')\n",
    "\n",
    "r = requests.get(url, cookies=cookies, timeout=1)\n",
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建一个session会话之后，客户端第一次发起请求登录账户，服务器自动把cookie信息保存在session对象中，发起第二次请求时requests 自动把session中的cookie信息发送给服务器，使之保持通信状态。\n",
    "\n",
    "```\n",
    "import requests\n",
    "# 构建会话\n",
    "session  = requests.Session()\n",
    "#　登录url\n",
    "session.post(login_url, data={username, password})\n",
    "#　登录后才能访问的url\n",
    "r = session.get(home_url)\n",
    "session.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 网络爬虫的“盗亦有道”\n",
    "\n",
    "网页对网络爬虫的限制,主要有两种:\n",
    "\n",
    "- 来源审查：判断User‐Agent进行限制\n",
    "检查来访HTTP协议头的User‐Agent域，只响应浏览器或友好爬虫的访问\n",
    "- 发布公告：Robots协议\n",
    "告知所有爬虫网站的爬取策略，要求爬虫遵守"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robots协议\n",
    "Robots Exclusion Standard，网络爬虫排除标准\n",
    "\n",
    "作用：\n",
    "网站告知网络爬虫哪些页面可以抓取，哪些不行\n",
    "\n",
    "形式：\n",
    "在网站根目录下的robots.txt文件\n",
    "\n",
    "Robots协议基本语法:\n",
    "\n",
    " \\*   代表所有，/代表根目录\n",
    " \n",
    "具体形式为\n",
    "User‐agent: \\*\n",
    "Disallow: /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 京东robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.jd.com/robots.txt\"\n",
    "r=requests.get(url,timeout=30)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来分析下这段内容的含义:\n",
    "\n",
    "User-agent: \\* \n",
    "\n",
    "Disallow: /?\\* \n",
    "\n",
    "Disallow: /pop/\\*.html \n",
    "\n",
    "Disallow: /pinpai/\\*.html?\\* \n",
    "\n",
    "这一段的意思对于任何爬虫,均不能访问后缀为/?\\*,/pop/\\*.html,/pinpai/\\*.html?\\* 的网页\n",
    "\n",
    "User-agent: EtaoSpider \n",
    "\n",
    "Disallow: / \n",
    "\n",
    "User-agent: HuihuiSpider \n",
    "\n",
    "Disallow: / \n",
    "\n",
    "User-agent: GwdangSpider \n",
    "\n",
    "Disallow: / \n",
    "\n",
    "User-agent: WochachaSpider \n",
    "\n",
    "Disallow: /\n",
    "\n",
    "这几段的意思是EtaoSpider,HuihuiSpider,GwdangSpider,WochachaSpider这几个网络爬虫不能访问京东的任何页面。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Request库网络爬取实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例1：京东商品页面的爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://item.jd.com/100002749549.html\"\n",
    "try:\n",
    "    r=requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    r.encoding=r.apparent_encoding\n",
    "    print(r.text[:1000])\n",
    "except:\n",
    "    print(\"爬取失败\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例2：亚马逊商品页面的爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.amazon.cn/gp/product/B01M8L5Z3Y\"\n",
    "try:\n",
    "    r=requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    r.encoding=r.apparent_encoding\n",
    "    print(r.text[2000:3000])\n",
    "except:\n",
    "    print(\"爬取失败\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.amazon.cn/gp/product/B01M8L5Z3Y\"\n",
    "try:\n",
    "    kv={'user-agent':'Mozilla/5.0'}\n",
    "    r=requests.get(url,headers=kv)\n",
    "    r.raise_for_status()\n",
    "    r.encoding=r.apparent_encoding\n",
    "    print(r.text[2000:3000])\n",
    "except:\n",
    "    print(\"爬取失败\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例3：百度搜索关键字提交\n",
    "\n",
    "百度的关键词接口：http://www.baidu.com/s?wd=keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "keyword=\"Python\"\n",
    "try:\n",
    "    kv={'wd':keyword}\n",
    "    r=requests.get(\"http://www.baidu.com/s\",params=kv)\n",
    "    print(r.request.url)\n",
    "    r.raise_for_status()\n",
    "    print(len(r.text))\n",
    "except:\n",
    "    print(\"爬取失败\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.文本解析\n",
    "* 网络请求库神器 Requests ，请求把数据返回来之后就要提取目标数据，不同的网站返回的内容通常有多种不同的格式，一种是 json 格式，这类数据对开发者来说最友好。另一种 XML 格式的，还有一种最常见格式的是 HTML 文档，今天就来讲讲如何从 HTML 中提取出感兴趣的数据\n",
    "\n",
    "  * BeautifulSoup解析网页\n",
    "  * Re正则表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 BeautifulSoup——HTML文本解析库\n",
    "* BeautifulSoup 是一个用于解析 HTML 文档的 Python 库，通过 BeautifulSoup，你只需要用很少的代码就可以提取出 HTML 中任何感兴趣的内容，此外，它还有一定的 HTML 容错能力，对于一个格式不完整的HTML 文档，它也可以正确处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安装 BeautifulSoup\n",
    "\n",
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML 标签\n",
    "学习 BeautifulSoup4 前有必要先对 HTML 文档有一个基本认识，如下代码，HTML 是一个树形组织结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<html>  \n",
    "    <head>\n",
    "     <title>hello, world</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>BeautifulSoup</h1>\n",
    "        <p>如何使用BeautifulSoup</p>\n",
    "    <body>\n",
    "</html>\n",
    "```\n",
    "* 它由很多标签（Tag）组成，比如 html、head、title等等都是标签\n",
    "\n",
    "* 一个标签对构成一个节点，比如 <html>...</html>是一个根节点\n",
    "\n",
    "* 节点之间存在某种关系，比如 h1 和 p 互为邻居，他们是相邻的兄弟（sibling）节点\n",
    "\n",
    "* h1 是 body 的直接子（children）节点，还是 html 的子孙（descendants）节点\n",
    "\n",
    "* body 是 p 的父（parent）节点，html 是 p 的祖辈（parents）节点\n",
    "\n",
    "* 嵌套在标签之间的字符串是该节点下的一个特殊子节点，比如 “hello, world” 也是一个节点，只不过没名字。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 BeautifulSoup\n",
    "构建一个 BeautifulSoup 对象需要两个参数，第一个参数是将要解析的 HTML 文本字符串，第二个参数告诉 BeautifulSoup  使用哪个解析器来解析 HTML。\n",
    "\n",
    "| 解析器\t| 使用方法\t| 优势\t| 劣势 |\n",
    "|--| -- |-- |-- |\n",
    "| Python标准库 |\tBeautifulSoup(markup, \"html.parser\")\t| Python的内置标准库、执行速度适中 、文档容错能力强 | Python 2.7.3 or 3.2.2)前的版本中文容错能力差|\n",
    "| lxml HTML 解析器\t| BeautifulSoup(markup, \"lxml\")\t| 速度快、文档容错能力强 | 需要安装C语言库 |\n",
    "| lxml XML 解析器\t| BeautifulSoup(markup, \"xml\") | 速度快、唯一支持XML的解析器 | 需要安装C语言库 |\n",
    "| html5lib\t| BeautifulSoup(markup, \"html5lib\")\t | 最好的容错性、以浏览器的方式解析文档、生成HTML5格式的文档 | 速度慢、不依赖外部扩展 |\n",
    "\n",
    "解析器负责把 HTML 解析成相关的对象，而 BeautifulSoup 负责操作数据（增删改查）。“html.parser” 是 Python 内置的解析器，“lxml” 则是一个基于c语言开发的解析器，它的执行速度更快，不过它需要额外安装\n",
    "\n",
    "通过 BeautifulSoup 对象可以定位到 HTML 中的任何一个标签节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "text = \"\"\"\n",
    "<html>  \n",
    "    <head>\n",
    "     <title >hello, world</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>BeautifulSoup</h1>\n",
    "        <p class=\"bold\">如何使用BeautifulSoup</p>\n",
    "        <p class=\"big\" id=\"key1\"> 第二个p标签</p>\n",
    "        <a href=\"http://foofish.net\">python</a>\n",
    "    </body>\n",
    "</html>  \n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 格式化输出 soup 对象的内容\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# title 标签\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p 标签\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.p.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p 标签的内容\n",
    "soup.p.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获取指定标签的子节点，类型是list\n",
    "type(soup.body.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeatifulSoup 将 HTML 抽象成为 4 类主要的数据类型，分别是Tag , NavigableString , BeautifulSoup，Comment 。每个标签节点就是一个Tag对象，NavigableString 对象一般是包裹在Tag对象中的字符串，BeautifulSoup 对象代表整个 HTML 文档。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(soup.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(soup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag\n",
    "\n",
    "Tag有很多方法和属性,现在介绍一下tag中最重要的属性: **name和attrs**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name**\n",
    "\n",
    "每个 Tag 都有一个名字，它对应 HTML 的标签名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.h1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.p.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **attrs**\n",
    "\n",
    "标签还可以有属性，属性的访问方式和字典是类似的，它返回一个列表对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.p.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.p['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NavigableString\n",
    "获取标签中的内容，直接使用 .stirng 即可获取，它是一个 NavigableString 对象，你可以显式地将它转换为 unicode 字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.p.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(soup.p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unicode_str = str(soup.p.string)\n",
    "unicode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(unicode_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本概念介绍完，现在可以正式进入主题了，如何从 HTML 中找到我们关心的数据？BeautifulSoup 提供了两种方式，一种是遍历，另一种是搜索，通常两者结合来完成查找任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 标签选择器\n",
    "\n",
    "#### 遍历文档树\n",
    "遍历文档树，顾名思义，就是是从根节点 html 标签开始遍历，直到找到目标元素为止，遍历的一个缺陷是，如果你要找的内容在文档的末尾，那么它要遍历整个文档才能找到它，速度上就慢了。遍历文档树的另一个缺点是只能获取到与之匹配的第一个子节点，例如，如果有两个相邻的 p 标签时，第二个标签就没法通过 .p 的方式获取，这是需要借用 next_sibling 属性获取相邻的节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    " </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')#传入解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1、选择元素**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.title)#将title标签里的内容包括其便签全部输出\n",
    "print(type(soup.title))\n",
    "print(soup.head)\n",
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2、获取名称**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.title.name)#获取标签的名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3、获取属性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.p.attrs['name'])#获取标签的属性\n",
    "print(soup.p['name'])#获取标签的属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4、获取内容**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.p.string)#获取标签内的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5、嵌套循环选择**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.head.title.string)#层层迭代，获取head标签里的title标签里的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<>…</>构成了所属关系，形成了标签的树形结构。这里将介绍对标签树的遍历，有三种遍历方式，分为下行遍历，上行遍历以及，平行遍历。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6、子节点和子孙节点**\n",
    "\n",
    "**标签树的下行遍历**\n",
    "\n",
    "属性| 说明\n",
    "--|--\n",
    ".contents| 子节点的列表，将<tag>所有儿子节点存入列表\n",
    ".children| 子节点的迭代类型，与.contents类似，用于循环遍历儿子节点\n",
    ".descendants| 子孙节点的迭代类型，包含所有子孙节点，用于循环遍历 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#方法一：获取p标签里的所有子节点，以list保存\n",
    "print(soup.p.contents)#获取p标签里的所有子节点，以list保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 方法二：获取p标签里的所有子节点，以迭代输出\n",
    "print(soup.p.children)\n",
    "for i, child in enumerate(soup.p.children):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 方法三：获取p标签里的所有子节点以及子孙节点（子节点对应的子节点）\n",
    "print(soup.p.descendants)\n",
    "for i, child in enumerate(soup.p.descendants):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7、父节点和祖先节点**\n",
    "\n",
    "**标签树的上行遍历**\n",
    "\n",
    "属性| 说明\n",
    "--|--\n",
    ".parent| 节点的父亲标签\n",
    ".parents| 节点先辈标签的迭代类型，用于循环遍历先辈节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#方法一：获取标签的父节点（前一级的节点）\n",
    "print(soup.a.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 方法二：获取标签所有的祖先节点（父节点的父节点的父节点。。。直到最顶层（把整个文档输出））\n",
    "print(list(enumerate(soup.a.parents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8、兄弟节点**\n",
    "\n",
    "**标签树的平行遍历**\n",
    "\n",
    "属性| 说明\n",
    "--|--\n",
    ".next_sibling |返回按照HTML文本顺序的下一个平行节点标签\n",
    ".previous_sibling |返回按照HTML文本顺序的上一个平行节点标签\n",
    ".next_siblings| 迭代类型，返回按照HTML文本顺序的后续所有平行节点标签\n",
    ".previous_siblings |迭代类型，返回按照HTML文本顺序的前续所有平行节点标签  \n",
    "注意平行遍历发生在同一个父节点下的各节点间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(list(enumerate(soup.a.next_siblings)))\n",
    "print(list(enumerate(soup.a.previous_siblings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 标准选择器\n",
    "\n",
    "#### 搜索文档树\n",
    "搜索文档树是通过指定标签名来搜索元素，还可以通过指定标签的属性值来精确定位某个节点元素，最常用的两个方法就是 find 和 find_all。这两个方法在 BeatifulSoup 和 Tag 对象上都可以被调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、find_all方法\n",
    "```\n",
    "find_all( name , attrs , recursive , text , **kwargs )\n",
    "第一个参数 name 是标签节点的名字。\n",
    "第二个参数是标签的class属性值\n",
    "kwargs 是标签的属性名值对\n",
    "可根据标签名、属性、内容查找文档\n",
    "```\n",
    "**name（标签名字选择）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.find_all('ul'))#查询所有便签为ul的元素\n",
    "print(type(soup.find_all('ul')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 嵌套搜索\n",
    "for ul in soup.find_all('ul'):\n",
    "    print(ul.find_all('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**attr（标签的属性选择）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用标签的的属性查找\n",
    "#方法一：使用字典参数查询\n",
    "print(soup.find_all(attrs={'id': 'list-1'}))\n",
    "print(soup.find_all(attrs={'name': 'elements'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#方法二：\n",
    "print(soup.find_all(id='list-1'))\n",
    "#只选择element属性的内容\n",
    "print(soup.find_all(class_='element'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 找到所有class属性为element的li标签\n",
    "soup.find_all(\"li\", \"element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 等效于\n",
    "soup.find_all(\"li\", class_=\"element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "soup.find_all(class_=re.compile(\"^list\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**text（文本选择）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#只返回text文本，适合内容匹配，不适合文本查询\n",
    "print(soup.find_all(text='Foo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.find_all(text=re.compile('a')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、find方法\n",
    "```\n",
    "find( name , attrs , recursive , text , **kwargs )\n",
    "```\n",
    "find返回单个元素，find_all返回所有元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.find('ul'))\n",
    "print(type(soup.find('ul')))\n",
    "print(soup.find('page'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、其他的一些find方法\n",
    "```\n",
    "find_parents() find_parent()\n",
    "find_parents()返回所有祖先节点，find_parent()返回直接父节点。\n",
    "\n",
    "find_next_siblings() find_next_sibling()\n",
    "find_next_siblings()返回后面所有兄弟节点，find_next_sibling()返回后面第一个兄弟节点。\n",
    "\n",
    "find_previous_siblings() find_previous_sibling()\n",
    "find_previous_siblings()返回前面所有兄弟节点，find_previous_sibling()返回前面第一个兄弟节点。\n",
    "\n",
    "find_all_next() find_next()\n",
    "find_all_next()返回节点后所有符合条件的节点, find_next()返回第一个符合条件的节点\n",
    "\n",
    "find_all_previous() 和 find_previous()\n",
    "find_all_previous()返回节点后所有符合条件的节点, find_previous()返回第一个符合条件的节点\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 CSS选择器\n",
    "通过select()直接传入CSS选择器即可完成选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、基本语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.select('.panel .panel-heading'))#.代表class，中间需要空格来分隔\n",
    "print(soup.select('ul li')) #选择ul标签下面的li标签\n",
    "print(soup.select('#list-2 .element')) #'#'代表id。这句的意思是查找id为\"list-2\"的标签下的，class=element的元素\n",
    "print(type(soup.select('ul')[0]))#打印节点类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、层层迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ul in soup.select('ul'):\n",
    "    print(ul.select('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、获取属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ul in soup.select('ul'):\n",
    "    print(ul['id'])#这两种方法都能获取标签的属性（id或其他）\n",
    "    print(ul.attrs['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4、获取内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for li in soup.select('li'):\n",
    "    print('Get Text:', li.get_text())\n",
    "    print('String:', li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总结\n",
    "BeatifulSoup 是一个用于操作 HTML 文档的 Python 库，初始化 BeatifulSoup 时，需要指定 HTML 文档字符串和具体的解析器。它有3类常用的数据类型，分别是 Tag、NavigableString、和 BeautifulSoup。查找 HTML元素有两种方式，分别是遍历文档树和搜索文档树，通常快速获取数据需要二者结合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 BeautifulSoup库网络爬取实战\n",
    "\n",
    "**中国大学排名定向爬虫**\n",
    "\n",
    "这里把程序分为三个部分    \n",
    "* 步骤1：从网络上获取大学排名网页内容 getHTMLText()   \n",
    "* 步骤2：提取网页内容中信息到合适的数据结构 fillUnivList()  \n",
    "* 步骤3：利用数据结构展示并输出结果 printUnivList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "\n",
    "def getHTMLText(url):\n",
    "    try:\n",
    "        r=requests.get(url,timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding=r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def fillUnivList(ulist,html):\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    for tr in soup.find(\"tbody\").children:\n",
    "        if isinstance(tr,bs4.element.Tag):\n",
    "            tds=tr('td')\n",
    "            ulist.append([tds[0].string,tds[1].string,tds[2].string,tds[3].string])\n",
    "\n",
    "def printUnivList(ulist,num):\n",
    "    print(\"{:^10}\\t{:^1}\\t{:^1}\\t{:^10}\".format(\"排名\",\"学校名称\",\"省市\",\"总分\"))\n",
    "    for i in range(num):\n",
    "        u=ulist[i]\n",
    "        print(\"{:^10}\\t{:^1}\\t{:^1}\\t{:^10}\".format(u[0],u[1],u[2],u[3]))\n",
    "        \n",
    "def main():\n",
    "    uinfo=[]\n",
    "    url=\"http://www.zuihaodaxue.cn/zuihaodaxuepaiming2019.html\"\n",
    "    html=getHTMLText(url)\n",
    "    fillUnivList(uinfo,html)\n",
    "    printUnivList(uinfo,20)#20个大学\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 Re——正则表达式\n",
    "\n",
    "正则表达式本身是一种小型的、高度专业化的编程语言，而在python中，通过内嵌集成re模块，程序员们可以直接调用来实现正则匹配。正则表达式模式被编译成一系列的字节码，然后由用C编写的匹配引擎执行。\n",
    "\n",
    "![](./img/re.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 re.match方法\n",
    "\n",
    "re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。\n",
    "\n",
    "函数语法：\n",
    "```\n",
    "re.match(pattern, string, flags=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "m = re.match('www', 'www.santostang.com')\n",
    "print (\"匹配的结果:  \", m)    \n",
    "print (\"匹配的起始与终点:  \", m.span()) \n",
    "print (\"匹配的起始位置:  \", m.start())\n",
    "print (\"匹配的终点位置:  \", m.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = re.match('san', 'www.santostang.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = \"Fat cats are smarter than dogs, is it right?\"\n",
    "m = re.match( r'(.*) are (.*?) dogs', line)\n",
    "print ('匹配的整句话', m.group(0))\n",
    "print ('匹配的第一个结果', m.group(1))\n",
    "print ('匹配的第二个结果', m.group(2))\n",
    "print ('匹配的结果列表', m.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 re.search方法\n",
    "\n",
    "在字符串中搜索匹配正则表达式的第一个位置\n",
    "\n",
    "函数语法：\n",
    "```\n",
    "re.search(pattern, string, flags=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "m_match = re.match('com', 'www.santostang.com')\n",
    "m_search = re.search('com', 'www.santostang.com')\n",
    "print(m_match)\n",
    "print(m_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(re.search('www', 'www.runoob.com').span())  # 在起始位置匹配\n",
    "print(re.search('com', 'www.runoob.com').span())         # 不在起始位置匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re.match与re.search的区别\n",
    "re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = \"Cats are smarter than dogs\";\n",
    " \n",
    "matchObj = re.match( r'dogs', line)\n",
    "if matchObj:\n",
    "   print (\"match --> matchObj.group() : \", matchObj.group())\n",
    "else:\n",
    "   print (\"No match!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matchObj = re.search( r'dogs', line, re.M|re.I)\n",
    "if matchObj:\n",
    "   print (\"search --> matchObj.group() : \", matchObj.group())\n",
    "else:\n",
    "   print (\"No match!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 re.compile方法\n",
    "compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。\n",
    "\n",
    "语法格式为：\n",
    "```\n",
    "re.compile(pattern[, flags])\n",
    "```\n",
    "\n",
    "参数：\n",
    "\n",
    "* pattern : 一个字符串形式的正则表达式\n",
    "* flags 可选，表示匹配模式，比如忽略大小写，多行模式等，具体参数为：\n",
    "  * re.I 忽略大小写\n",
    "  * re.L 表示特殊字符集 \\w, \\W, \\b, \\B, \\s, \\S 依赖于当前环境\n",
    "  * re.M 多行模式\n",
    "  * re.S 即为' . '并且包括换行符在内的任意字符（' . '不包括换行符）\n",
    "  * re.U 表示特殊字符集 \\w, \\W, \\b, \\B, \\d, \\D, \\s, \\S 依赖于 Unicode 字符属性数据库\n",
    "  * re.X 为了增加可读性，忽略空格和' # '后面的注释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\d+')                    # 用于匹配至少一个数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = pattern.match('one12twothree34four')        # 查找头部，没有匹配\n",
    "m.group(0)   # 可省略 0\n",
    "m.start(0)   # 可省略 0\n",
    "m.end(0)     # 可省略 0\n",
    "m.span(0)    # 可省略 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = pattern.match('one12twothree34four', 2, 10) # 从'e'的位置开始匹配，没有匹配\n",
    "m.group(0)   # 可省略 0\n",
    "m.start(0)   # 可省略 0\n",
    "m.end(0)     # 可省略 0\n",
    "m.span(0)    # 可省略 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = pattern.match('one12twothree34four', 3, 10) # 从'1'的位置开始匹配，正好匹配\n",
    "m.group(0)   # 可省略 0\n",
    "m.start(0)   # 可省略 0\n",
    "m.end(0)     # 可省略 0\n",
    "m.span(0)    # 可省略 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 re.findall 方法\n",
    "\n",
    "搜索字符串，以列表形式返回所有匹配的子串\n",
    "\n",
    "语法格式为：\n",
    "```\n",
    "findall(string[, pos[, endpos]])\n",
    "```\n",
    "\n",
    "参数：\n",
    "\n",
    "* string 待匹配的字符串。\n",
    "* pos 可选参数，指定字符串的起始位置，默认为 0。\n",
    "* endpos 可选参数，指定字符串的结束位置，默认为字符串的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\d+')   # 查找数字\n",
    "result1 = pattern.findall('runoob 123 google 456')\n",
    "result2 = pattern.findall('run88oob1google456')\n",
    " \n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_match = re.match('[0-9]+', '12345 is the first number, 23456 is the sencond')\n",
    "m_search = re.search('[0-9]+', 'The first number is 12345, 23456 is the sencond')\n",
    "m_findall = re.findall('[0-9]+', '12345 is the first number, 23456 is the sencond')\n",
    "print (m_match.group())\n",
    "print (m_search.group())\n",
    "print (m_findall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 re.split方法 \n",
    "split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下：\n",
    "\n",
    "re.split(pattern, string[, maxsplit=0, flags=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.split('\\W+', 'runoob, runoob, runoob.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.split('\\W+', 'runoob, runoob, runoob.', 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 常用匹配规则\n",
    "\n",
    "\n",
    "* 常用操作符\n",
    "\n",
    "操作符| 说明| 实例\n",
    "--|--|--\n",
    ". |表示任何单个字符|\n",
    "[ ] |字符集，对单个字符给出取值范围 |[abc]表示a、 b、 c，[a‐z]表示a到z单个字符\n",
    "[^ ] |非字符集，对单个字符给出排除范围 |[^abc]表示非a或b或c的单个字符\n",
    "\\* |前一个字符0次或无限次扩展 |abc\\* 表示 ab、 abc、 abcc、 abccc等\n",
    "\\+ |前一个字符1次或无限次扩展 |abc+ 表示 abc、 abcc、 abccc等\n",
    "? |前一个字符0次或1次扩展| abc? 表示 ab、 abc\n",
    "&#124;| 左右表达式任意一个 |abc&#124;def 表示 abc、 def\n",
    "{m} |扩展前一个字符m次 |ab{2}c表示abbc\n",
    "{m,n} |扩展前一个字符m至n次（含n） |ab{1,2}c表示abc、 abbc\n",
    "^| 匹配字符串开头 |^abc表示abc且在一个字符串的开头\n",
    "\\$| 匹配字符串结尾 |abc$表示abc且在一个字符串的结尾\n",
    "( ) |分组标记，内部只能使用 &#124; 操作符 |(abc)表示abc，(abc&#124;def)表示abc、 def\n",
    "\\d |数字，等价于[0‐9]|\n",
    "\\w |单词字符，等价于[A‐Za‐z0‐9_]|\n",
    "\n",
    "* 经典例子\n",
    "\n",
    "正则表达式|对应字符串\n",
    "--|--\n",
    "^[A‐Za‐z]+\\$|由26个字母组成的字符串\n",
    "^[A‐Za‐z0‐9]+\\$|由26个字母和数字组成的字符串\n",
    "^‐?\\d+\\$|整数形式的字符串\n",
    "^[0‐9]\\*[1‐9][0‐9]\\*\\$|正整数形式的字符串\n",
    "[1‐9]\\d{5}|中国境内邮政编码，6位\n",
    "[\\u4e00‐\\u9fa5]|匹配中文字符\n",
    "\\d{3}‐\\d{8}&#124;\\d{4}‐\\d{7}|国内电话号码，010‐68913536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7 正则匹配实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "html = '''<div id=\"songs-list\">\n",
    "    <h2 class=\"title\">经典老歌</h2>\n",
    "    <p class=\"introduction\">\n",
    "        经典老歌列表\n",
    "    </p>\n",
    "    <ul id=\"list\" class=\"list-group\">\n",
    "        <li data-view=\"2\">一路上有你</li>\n",
    "        <li data-view=\"7\">\n",
    "            <a href=\"/2.mp3\" singer=\"任贤齐\">沧海一声笑</a>\n",
    "        </li>\n",
    "        <li data-view=\"4\" class=\"active\">\n",
    "            <a href=\"/3.mp3\" singer=\"齐秦\">往事随风</a>\n",
    "        </li>\n",
    "        <li data-view=\"6\"><a href=\"/4.mp3\" singer=\"beyond\">光辉岁月</a></li>\n",
    "        <li data-view=\"5\"><a href=\"/5.mp3\" singer=\"陈慧琳\">记事本</a></li>\n",
    "        <li data-view=\"5\">\n",
    "            <a href=\"/6.mp3\" singer=\"邓丽君\">但愿人长久</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.search('<li.*?active.*?singer=\"(.*?)\">(.*?)</a>', html, re.S)\n",
    "if result:\n",
    "    print(result.group(1), result.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.search('<li.*?singer=\"(.*?)\">(.*?)</a>', html, re.S)\n",
    "if result:\n",
    "    print(result.group(1), result.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.search('<li.*?singer=\"(.*?)\">(.*?)</a>', html)\n",
    "if result:\n",
    "    print(result.group(1), result.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.findall('<li.*?href=\"(.*?)\".*?singer=\"(.*?)\">(.*?)</a>', html, re.S)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = re.sub('<a.*?>|</a>', '', html)\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.findall('<li.*?>(.*?)</li>', html, re.S)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.动态网页\n",
    "* Selenium是一个用于测试网站的自动化测试工具，支持各种浏览器包括Chrome、Firefox、Safari等主流界面浏览器，同时也支持phantomJS无界面浏览器，爬虫中主要用来解决JavaScript渲染问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安装Selenium\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 看看Selenium.Webdriver支持哪些浏览器\n",
    "from selenium import webdriver\n",
    "help(webdriver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 驱动下载\n",
    "\n",
    "安装ChromeDriver, 该工具供selenium使用Chrome.\n",
    "\n",
    "ChromeDriver: http://npm.taobao.org/mirrors/chromedriver/\n",
    "\n",
    "下载前先查看本地环境的Chrome版本, 然后去上面的link中下载对应的ChromeDriver版本."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selenium声明浏览器对象\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 访问页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#webdriver.Firefox()\n",
    "driver = webdriver.Chrome()     # 创建Chrome对象.\n",
    "# 操作这个对象.\n",
    "driver.get('https://www.baidu.com')     # get方式访问百度.\n",
    "time.sleep(10)\n",
    "driver.quit()   # 使用完, 记得关闭浏览器, 不然chromedriver.exe进程为一直在内存中."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单个元素查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 申明一个浏览器对象\n",
    "browser = webdriver.Chrome()\n",
    "# 使用浏览器访问淘宝\n",
    "browser.get('https://www.taobao.com')\n",
    "# 在响应结果中通过id查找元素\n",
    "input_first = browser.find_element_by_id('q')\n",
    "# 在响应结果中通过css选择器查找元素\n",
    "input_second = browser.find_element_by_css_selector('#q')\n",
    "# 在响应结果中通过xpath查找元素\n",
    "input_third = browser.find_element_by_xpath('//*[@id=\"q\"]')\n",
    "print(input_first)\n",
    "print(input_second)\n",
    "print(input_third)\n",
    "time.sleep(10)\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查找后返回的是一个Webelement对象。\n",
    "\n",
    "查找多个元素: 将其中的element加上一个s，则是对应的多个查找方法。\n",
    "\n",
    "![](img/driver.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多个元素查找\n",
    "\n",
    "其实多个元素和单个元素的区别，举个例子：find_elements,单个元素是find_element,其他使用上没什么区别，通过其中的一个例子演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "browser.get(\"http://www.taobao.com\")\n",
    "lis = browser.find_elements_by_css_selector('.service-bd li')\n",
    "print(lis)\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 元素交互操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "driver = webdriver.Chrome()     # 创建Chrome对象.\n",
    "# 操作这个对象.\n",
    "driver.get('https://www.baidu.com')     # get方式访问百度.\n",
    "\n",
    "print('Before search================')\n",
    "time.sleep(5)\n",
    "# 打印当前页面title\n",
    "title = driver.title\n",
    "print(title)\n",
    "\n",
    "# 打印当前页面URL\n",
    "now_url = driver.current_url\n",
    "print(now_url)\n",
    "\n",
    "driver.find_element_by_id(\"kw\").send_keys(\"python\")\n",
    "driver.find_element_by_id(\"su\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "print('After search================')\n",
    "\n",
    "# 再次打印当前页面title\n",
    "title = driver.title\n",
    "print(title)\n",
    "\n",
    "# 打印当前页面URL\n",
    "now_url = driver.current_url\n",
    "print(now_url)\n",
    "\n",
    "# 获取结果数目\n",
    "user = driver.find_element_by_class_name('nums').text\n",
    "print(user)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#关闭所有窗口\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前进后退"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.baidu.com/')\n",
    "browser.get('https://www.taobao.com/')\n",
    "browser.get('https://www.python.org/')\n",
    "browser.back()\n",
    "time.sleep(1)\n",
    "browser.forward()\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选项卡管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.baidu.com')\n",
    "browser.execute_script('window.open()')\n",
    "print(browser.window_handles)\n",
    "browser.switch_to_window(browser.window_handles[1])\n",
    "browser.get('https://www.taobao.com')\n",
    "browser.close()\n",
    "time.sleep(1)\n",
    "browser.switch_to_window(browser.window_handles[0])\n",
    "browser.get('https://python.org')\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
