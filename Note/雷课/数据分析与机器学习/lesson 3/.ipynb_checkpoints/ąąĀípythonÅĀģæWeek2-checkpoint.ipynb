{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "课程地址:https://www.icourse163.org/course/BIT-1001870001   \n",
    "笔记内容结合课件整理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对北理爬虫课程第二周内容回顾,本周主要介绍了Beautiful Soup库以及信息标记与提取方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Beautiful Soup库入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup库是一个解析网络数据的python库，下面使用下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://python123.io/ws/demo.html')\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = r.text\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(demo,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和r.text的结构相比，使用BeautifulSoup库解析之后的数据更加清晰，下面回顾下BeautifulSoup类的基本元素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup类的基本元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "```\n",
    "<p class=“title”> … </p>\n",
    "```\n",
    "</center>\n",
    "\n",
    "基本元素|说明\n",
    "--|---\n",
    "Tag| 标签，最基本的信息组织单元，分别用<>和</>标明开头和结尾\n",
    "Name| 标签的名字，```<p>…</p>```的名字是'p'，格式：```<tag>.name```\n",
    "Attributes |标签的属性，字典形式组织，格式：```<tag>.attrs```\n",
    "NavigableString |标签内非属性字符串，```<>…</>```中字符串，格式：```<tag>.string```\n",
    "Comment |标签内字符串的注释部分，一种特殊的Comment类型\n",
    "\n",
    "下面详细看下这些基本元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag 标签  \n",
    "\n",
    "基本元素|说明\n",
    "--|--\n",
    "Tag| 标签，最基本的信息组织单元，分别用<>和</>标明开头和结尾\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(demo,'html.parser')\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任何存在于HTML语法中的标签都可以用```soup.<tag>```访问获得\n",
    "当HTML文档中存在多个相同```<tag>```对应内容时，```soup.<tag>```返回第一个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag的name（名字）  \n",
    "基本元素| 说明\n",
    "--|--\n",
    "Name| 标签的名字，```<p>…</p>```的名字是'p'，格式：```<tag>.name```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a.parent.parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个```<tag>```都有自己的名字，通过```<tag>.name```获取，字符串类型。   这里的parent是父节点的意思，后面还会具体介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag的attrs（属性）   \n",
    "基本元素| 说明\n",
    "--|--\n",
    "Attributes |标签的属性，字典形式组织，格式：```<tag>.attrs```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = soup.a\n",
    "tag.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag.attrs['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag.attrs['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来看下属性以及标签的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tag))\n",
    "print(type(tag.attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个<tag>可以有0或多个属性，字典类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag的NavigableString\n",
    "基本元素| 说明\n",
    "--|--\n",
    "NavigableString| 标签内非属性字符串，```<>…</>```中字符串，格式：```<tag>.string```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag的Comment\n",
    "基本元素| 说明\n",
    "--|--\n",
    "Comment| 标签内字符串的注释部分，一种特殊的Comment类型   \n",
    "这里需要注意注释类型和NavigableString不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsoup = BeautifulSoup(\"<b><!--This is a comment--></b><p>This is not a comment</p>\",\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsoup.b.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(newsoup.b.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsoup.p.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(newsoup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于bs4库的HTML内容遍历方法    \n",
    "这里回顾下最开始的时候BeautifulSoup库解析之后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<>…</>```构成了所属关系，形成了标签的树形结构。这里将介绍对标签树的遍历，有三种遍历方式，分为下行遍历，上行遍历以及，平行遍历。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标签树的下行遍历\n",
    "属性| 说明\n",
    "--|--\n",
    ".contents| 子节点的列表，将<tag>所有儿子节点存入列表\n",
    ".children| 子节点的迭代类型，与.contents类似，用于循环遍历儿子节点\n",
    ".descendants| 子孙节点的迭代类型，包含所有子孙节点，用于循环遍历\n",
    "BeautifulSoup类型是标签树的根节点   \n",
    "来看下这些基本属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(demo,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.body.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.contents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签树的下行遍历有两种，分别为遍历儿子节点以及遍历子孙节点,下面分别看一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历儿子节点\n",
    "for child in soup.body.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历子孙节点\n",
    "for child in soup.body.descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标签树的上行遍历\n",
    "属性| 说明\n",
    "--|--\n",
    ".parent| 节点的父亲标签\n",
    ".parents| 节点先辈标签的迭代类型，用于循环遍历先辈节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(demo,\"html.parser\")\n",
    "for parent in soup.a.parents:\n",
    "    if parent is None:\n",
    "        print(parent)\n",
    "    else:\n",
    "        print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为遍历所有先辈节点，包括soup本身，所以要区别判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标签树的平行遍历\n",
    "属性| 说明\n",
    "--|--\n",
    ".next_sibling |返回按照HTML文本顺序的下一个平行节点标签\n",
    ".previous_sibling |返回按照HTML文本顺序的上一个平行节点标签\n",
    ".next_siblings| 迭代类型，返回按照HTML文本顺序的后续所有平行节点标签\n",
    ".previous_siblings |迭代类型，返回按照HTML文本顺序的前续所有平行节点标签  \n",
    "注意平行遍历发生在同一个父节点下的各节点间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历后续节点\n",
    "for sibling in soup.a.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历前续节点\n",
    "for sibling in soup.a.previous_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.信息标记与提取方法\n",
    "这里老师介绍了三种信息标记的方法，分别是XML，JSON以及YAML，特点如下：\n",
    "\n",
    "标记方式|特点\n",
    "--|--\n",
    "XML| 最早的通用信息标记语言，可扩展性好，但繁琐\n",
    "JSON| 信息有类型，适合程序处理(js)，较XML简洁\n",
    "YAML |信息无类型，文本信息比例最高，可读性好\n",
    "\n",
    "\n",
    "再来看下信息提取的一般方法\n",
    "\n",
    "方法一：完整解析信息的标记形式，再提取关键信息  \n",
    "XML JSON YAML  \n",
    "需要标记解析器，例如：bs4库的标签树遍历  \n",
    "优点：信息解析准确  \n",
    "缺点：提取过程繁琐，速度慢  \n",
    "\n",
    "方法二：无视标记形式，直接搜索关键信息  \n",
    "搜索  \n",
    "对信息的文本查找函数即可  \n",
    "优点：提取过程简洁，速度较快  \n",
    "缺点：提取结果准确性与信息内容相关  \n",
    "\n",
    "融合方法：结合形式解析与搜索方法，提取关键信息  \n",
    "XML JSON YAML 搜索  \n",
    "需要标记解析器及文本查找函数  \n",
    "\n",
    "来看一个实例，这里要找HTML中所有的超链接，首先找到a标签，其次搜索关键信息'href'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着来看下上面使用的find_all方法  \n",
    "<>.find_all(name, attrs, recursive, string, **kwargs)  \n",
    "返回一个列表类型，存储查找的结果  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name : 对标签名称的检索字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all(True):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for tag in soup.find_all(re.compile('b')):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里re是正则表达式库，re.compile('b')的意思是含有'b'的字符串，<>.find_all(re.compile('b'))找到了标签名字中含有'b'的的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attrs: 对标签属性值的检索字符串，可标注属性检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p','course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(id='link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(id=re.compile('link'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recursive: 是否对子孙全部检索，默认True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a',recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "string: <>…</>中字符串区域的检索字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(string='Basic Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(string=re.compile('Python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于find_all使用的比较多，BS4库提供了简写方法  \n",
    "\n",
    "- <tag>(..) 等价于 <tag>.find_all(..)\n",
    "- soup(..) 等价于 soup.find_all(..)\n",
    "\n",
    "\n",
    "最后再总结下find_all的全部参数:  \n",
    "<>.find_all(name, attrs, recursive, string, **kwargs)  \n",
    "- name : 对标签名称的检索字符串\n",
    "- attrs: 对标签属性值的检索字符串，可标注属性检索\n",
    "- recursive: 是否对子孙全部检索，默认True\n",
    "- string: <>…</>中字符串区域的检索字符串  \n",
    "\n",
    "除了find_all方法，还有以下一些方法，使用方法和find_all类似： \n",
    "\n",
    "方法| 说明\n",
    "--|--\n",
    "<>.find() |搜索且只返回一个结果，同.find_all()参数\n",
    "<>.find_parents() |在先辈节点中搜索，返回列表类型，同.find_all()参数\n",
    "<>.find_parent() |在先辈节点中返回一个结果，同.find()参数\n",
    "<>.find_next_siblings() |在后续平行节点中搜索，返回列表类型，同.find_all()参数\n",
    "<>.find_next_sibling() |在后续平行节点中返回一个结果，同.find()参数\n",
    "<>.find_previous_siblings() |在前序平行节点中搜索，返回列表类型，同.find_all()参数\n",
    "<>.find_previous_sibling() |在前序平行节点中返回一个结果，同.find()参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.“中国大学排名定向爬虫”\n",
    "\n",
    "这里把程序分为三个部分    \n",
    "步骤1：从网络上获取大学排名网页内容 getHTMLText()   \n",
    "步骤2：提取网页内容中信息到合适的数据结构 fillUnivList()  \n",
    "步骤3：利用数据结构展示并输出结果 printUnivList()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "\n",
    "def getHTMLText(url):\n",
    "    try:\n",
    "        r=requests.get(url,timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding=r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def fillUnivList(ulist,html):\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    for tr in soup.find(\"tbody\").children:\n",
    "        if isinstance(tr,bs4.element.Tag):\n",
    "            tds=tr('td')\n",
    "            ulist.append([tds[0].string,tds[1].string,tds[2].string])\n",
    "\n",
    "def printUnivList(ulist,num):\n",
    "    print(\"{:^10}\\t{:^6}\\t{:^10}\".format(\"排名\",\"学校名称\",\"总分\"))\n",
    "    for i in range(num):\n",
    "        u=ulist[i]\n",
    "        print(\"{:^10}\\t{:^6}\\t{:^10}\".format(u[0],u[1],u[2]))\n",
    "        \n",
    "def main():\n",
    "    uinfo=[]\n",
    "    url=\"http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html\"\n",
    "    html=getHTMLText(url)\n",
    "    fillUnivList(uinfo,html)\n",
    "    printUnivList(uinfo,20)#20个大学\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "这里看到格式，输出不整齐，下面改进下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "\n",
    "def getHTMLText(url):\n",
    "    try:\n",
    "        r=requests.get(url,timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding=r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def fillUnivList(ulist,html):\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    for tr in soup.find(\"tbody\").children:\n",
    "        if isinstance(tr,bs4.element.Tag):\n",
    "            tds=tr('td')\n",
    "            ulist.append([tds[0].string,tds[1].string,tds[2].string])\n",
    "\n",
    "def printUnivList(ulist,num):\n",
    "    tplt=\"{0:^10}\\t{1:{3}^10}\\t{2:^10}\"\n",
    "    print(tplt.format(\"排名\",\"学校名称\",\"总分\",chr(12288)))\n",
    "    for i in range(num):\n",
    "        u=ulist[i]\n",
    "        print(tplt.format(u[0],u[1],u[2],chr(12288)))\n",
    "        \n",
    "def main():\n",
    "    uinfo=[]\n",
    "    url=\"http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html\"\n",
    "    html=getHTMLText(url)\n",
    "    fillUnivList(uinfo,html)\n",
    "    printUnivList(uinfo,20)#20个大学\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
