{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <center>网络数据获取——综合实践</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 课程内容\n",
    "\n",
    "* 1.下载链接文件\n",
    "* 2.解析网页爬取数据\n",
    "* 3.动态网页数据爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 1.下载链接文件\n",
    "\n",
    "* 2019全国知识图谱与语义计算大会评测论文集 https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html\n",
    "```py\n",
    "# 引入所需包\n",
    "import requests\n",
    "import time\n",
    "```\n",
    "练习通过URL抓取链接文件，使用`open`存储到本地。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 普通下载\n",
    "\n",
    "```py\n",
    "r = requests.get(url)\n",
    "f = open(file_name, 'wb')\n",
    "f.write(r.content)\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 有效率的下载\n",
    "直接使用f.write的话，是先把r.content全部写到内存里，在写到硬盘当中，显然这样既不效率且占用内存，因此另一种更有效率的下载方式是以文件流的形式下载\n",
    "* 把get()里的stream参数设置为True\n",
    "* 使用for...in的形式写文件\n",
    "```py\n",
    "r = requests.get(url, stream=True)\n",
    "f = open(file_name, 'wb')\n",
    "for a in r.iter_content(chunk_size=32):  # iter是iter\n",
    "    f.write(a)\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小练习\n",
    "# 爬取会议论文集：https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html 中文知识图谱问答\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬取静态数据可以分为两类，一类是**调用API爬取数据**，一类是**解析网页爬取数据**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.解析网页爬取数据\n",
    "\n",
    "* http://quotes.toscrape.com/\n",
    "\n",
    "```py\n",
    "# 引入所需包\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "...\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "```\n",
    "练习抓取`html`静态文件，利用`BeautifulSoup`解析文件，使用`pandas`存储到本地。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分析页面获取数据\n",
    "```\n",
    "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
    "        <span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
    "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
    "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
    "        </span>\n",
    "        <div class=\"tags\">\n",
    "            Tags:\n",
    "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"change,deep-thoughts,thinking,world\" /    >             \n",
    "            <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>            \n",
    "            <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>            \n",
    "            <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>            \n",
    "            <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>            \n",
    "        </div>\n",
    "    </div>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小练习\n",
    "# 爬取一个城市近7天的天气情况 http://www.weather.com.cn/weather/101010100.shtml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.爬取动态数据\n",
    "* http://quotes.toscrape.com/js/\n",
    "\n",
    "```py\n",
    "# 引入所需包\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "...\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n",
    "time.sleep(5)\n",
    "browser.close()\n",
    "html = browser.page_source #获取网页信息\n",
    "...\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "```\n",
    "练习抓取`html`动态文件，利用`BeautifulSoup`解析文件，使用`pandas`存储到本地。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 方法一\n",
    "* 传统方法爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 思考问题：为什么没有获取到数据？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 方法二\n",
    "* selenium模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小练习\n",
    "# 水木社区每日十大话题 http://www.newsmth.net/nForum/#!board/ShiDa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1、构造URL\n",
    "如何分析网页请求构造抓取URL队列。\n",
    "```\n",
    "http://quotes.toscrape.com\n",
    "```\n",
    "\n",
    "### 2、数据请求\n",
    "#### 2.1 静态网页\n",
    "**request**\n",
    "* get：一般情况使用\n",
    "* post：如果向服务器提交数据，进行交互（用户名、密码）\n",
    "\n",
    "注意事项：1、伪装请求报头headers={user-agent}；2、中文字符编码encoding=utf-8\n",
    "#### 2.2 动态网页\n",
    "**selenium**\n",
    "* 代替request来请求数据\n",
    "\n",
    "注意事项：浏览器驱动及版本\n",
    "\n",
    "### 3、解析数据\n",
    "数据格式：**二进制content**、**对象Json**、**文本text**\n",
    "\n",
    "**beautifulsoup**\n",
    "* 三个对象：Soup、Tag、String\n",
    "* 两个方法：1) 查找标签：**find_all** ； 2) 查找样式：**select**\n",
    "\n",
    "### 4、保存数据\n",
    "pandas—>DataFrame—>to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
