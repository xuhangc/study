{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>自然语言处理--补充知识</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课程内容\n",
    "* 1.实体识别介绍\n",
    "* 2.简单模型实践\n",
    "* 3.复杂模型实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.实体识别介绍\n",
    "\n",
    "命名实体识别（Named Entity Recognition，NER）是NLP中一项非常基础的任务。NER是信息提取、问答系统、句法分析、机器翻译等众多NLP任务的重要基础工具。\n",
    "\n",
    "**实体识别**\n",
    "\n",
    "简单的理解，实体识别就是将你想要获取到的实体类型，从一句话里面挑出来的过程。\n",
    "\n",
    "|小明|在|北京大学|的|燕园|读书|\n",
    "| ---- |:----:|:----:|:----:|:----:|:----:|\n",
    "|PER||ORG||LOC|&nbsp;|\n",
    "\n",
    "如上面的例子所示，句子“小明在北京大学的燕园看了中国男篮 的一场比赛”，通过NER模型，将“小明 ”以PER，“北京大学”以ORG，“燕园”以LOC为类别分别挑了出来。\n",
    "\n",
    "**数据标注**\n",
    "\n",
    "采用BIO三位标注(B-begin，I-inside，O-outside)方式进行数据标注，把不属于实体的字用O标注，把实体用BI规则标注，最后按照BIO规则把实体提取出来。\n",
    "\n",
    "|小|明|在|北|京|大|学|的|燕|园|读|书|\n",
    "| :-: |:---:|:---:|:---:|:---:|:---:|:---:|:---:| :---:|:---:|:---:| ---:|\n",
    "|B-PER|I-PER|O|B-ORG|I-ORG|I-ORG|I-ORG|O|B-LOC|I-LOC|O|O|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 简单模型实践\n",
    "\n",
    "**Bidirectional LSTM**\n",
    "\n",
    "![](images/ner.png)\n",
    "\n",
    "* 图中B-Person、I-Person代表人名首字、人名非首字，B-Organization、I-Organization代表组织机构名首字、组织机构名非首字，O代表该字不属于命名实体的一部分。\n",
    "* 图中输入是word embedding,使用双向lstm进行encode，对于lstm的hidden层，接入一个大小为[hidden_dim,num_label]的一个全连接层就可以得到每一个step对应的每个label的概率，也就是上图黄色框的部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\") #向下填充，用前一个非缺失值去填充该缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 查看数据\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计单词个数\n",
    "words = list(set(data[\"Word\"].values))\n",
    "\n",
    "words.append(\"UNKNOWN\")\n",
    "words.append(\"ENDPAD\")\n",
    "\n",
    "n_words = len(words)\n",
    "print(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计标签个数\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 按句子分割数据\n",
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "grouped = data.groupby(\"Sentence\").apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算句子长度\n",
    "sentence_lens = [len(s) for s in grouped]\n",
    "sentence_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计句子长度分布\n",
    "import numpy as np\n",
    "print(\"最短文本长度=\", min(sentence_lens))\n",
    "print(\"最长文本长度=\", max(sentence_lens))\n",
    "print(\"平均文本长度=\", np.mean(sentence_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 绘制句子长度分布图\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sentence_lens, bins=range(min(sentence_lens), max(sentence_lens)+2, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将Series转换为List\n",
    "sentences = [s for s in grouped]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx[\"ENDPAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_data = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "x_data = pad_sequences(maxlen=max_len, sequences=x_data, padding=\"post\", value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "y_data = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y_data = pad_sequences(maxlen=max_len, sequences=y_data, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_data[0])\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_data = to_categorical(y_data, num_classes=n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_data[0])\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,CuDNNLSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=100, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Dense(n_tags, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 模型训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=1, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 复杂模型实践\n",
    "\n",
    "**BiLSTM与CRF**\n",
    "![](images/crf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**keras-contrib安装**\n",
    "```py\n",
    "pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiLSTM-CRF模型**\n",
    "```py\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,CuDNNLSTM\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=100, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "crf = CRF(n_tags, sparse_target=True)\n",
    "model.add(crf)\n",
    "model.summary()\n",
    "\n",
    "model.compile('adam', loss=crf_loss, metrics=[crf_viterbi_accuracy])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小练习\n",
    "# 基于BiLSTM-CRF模型的实体识别\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
