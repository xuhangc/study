{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <center>Python课程实践--Scikit-learn 案例</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 课程内容\n",
    "\n",
    "### 实践题目\n",
    "#### 医疗健康疾病预测\n",
    "\n",
    "* 该数据集最初来自国家糖尿病/消化/肾脏疾病研究所。数据集的目标是基于数据集中包含的某些诊断测量来诊断性的预测 患者是否患有糖尿病。\n",
    "* 从较大的数据库中选择这些实例有几个约束条件。尤其是，这里的所有患者都是Pima印第安至少21岁的女性。\n",
    "* 数据集由多个医学预测变量和一个目标变量组成Outcome。预测变量包括患者的怀孕次数、BMI、胰岛素水平、年龄等。\n",
    "\n",
    "### 数据文件\n",
    "* diabetes.csv\n",
    "\n",
    "### 本节任务\n",
    "* 针对医疗数据的特点进行数据清洗、特征工程（寻找特征，特征组合）\n",
    "* 尝试的多种算法模型，给出诊断结果的同时，提供合理的解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 【1】Pregnancies：怀孕次数 \n",
    "- 【2】Glucose：葡萄糖 \n",
    "- 【3】BloodPressure：血压 (mm Hg) \n",
    "- 【4】SkinThickness：皮层厚度 (mm) \n",
    "- 【5】Insulin：胰岛素 2小时血清胰岛素（mu U / ml \n",
    "- 【6】BMI：体重指数 （体重/身高）^2 \n",
    "- 【7】DiabetesPedigreeFunction：糖尿病谱系功能 \n",
    "- 【8】Age：年龄 （岁） \n",
    "- 【9】Outcome：类标变量 （0或1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN算法介绍\n",
    "KNN是一种有监督的机器学习算法，可以解决分类问题，也可以解决回归问题。\n",
    "\n",
    "算法流程 \n",
    "对每一个未知点执行：\n",
    "\n",
    "\n",
    "* 计算未知点到所有已知类别点的距离\n",
    "* 按距离排序（升序）\n",
    "* 选取其中前k个与未知点离得最近的点\n",
    "* 统计k个点中各个类别的个数\n",
    "* 上述k个点里类别出现频率最高的作为未知点的类别\n",
    "\n",
    "\n",
    "* 优点： \n",
    "简单有效、易理解\n",
    "\n",
    "* 缺点： \n",
    "k近邻需要保存全部数据集，因此对内存消耗大，当数据集较大时对设备要求非常高； \n",
    "需要计算每个未知点到全部已知点的距离，可能会很耗时； \n",
    "分类结果不易理解\n",
    "\n",
    "![Data Layout](images/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = pd.read_csv('data/diabetes.csv') # DataFrame\n",
    "print('dataset shape {}'.format(data.shape))\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()  #看是否有空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() #看是否有异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=data.corr()\n",
    "corr[corr>0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc是基于索引位来选取数据集，0:4就是选取 0，1，2，3这四行，需要注意的是这里是前闭后开集合\n",
    "# 使用 iloc 进行行列混合选择 \n",
    "#data.iloc[0:5] 数据中的第 1-5 行 \n",
    "# data.iloc[:, 0:2]  选择数据中的前2列和所有行 \n",
    "# data.iloc[[0, 3, 6, 24], [0, 5, 6]] 选择第 1,4,7,25行 和 第 1,6,7 列 \n",
    "# data.iloc[0:5, 5:8]  #选择第1-6行 和 6-9列\n",
    "# 含有特征的数据集\n",
    "X = data.iloc[:,0:8]\n",
    "# 标记数据\n",
    "Y = data.iloc[:,8]\n",
    "print('shape of X {} ; shape of Y {}'.format(X.shape,Y.shape))\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 将数据集划分为训练集和测试集，其中测试数据为20%\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\n",
    "#我们使用三种算法对数据进行拟合即普通的k-均值算法，带权重的k-均值算法和指定半径的k-均值算法。\n",
    "#models.append方法就是将一个元素放入models列表中\n",
    "models = []\n",
    "models.append(('KNN',KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('KNN with weights',KNeighborsClassifier(n_neighbors=7,weights='distance')))\n",
    "models.append(('Radius Neighbors',RadiusNeighborsClassifier(n_neighbors=7,radius=500.0)))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name,model in models:\n",
    "    #fit(x,y)传两个参数的是有监督学习的算法，fit(x)传一个参数的是无监督学习的算法，比如降维、特征提取、标准化\n",
    "    model.fit(X_train,Y_train)\n",
    "    results.append((name,model.score(X_test,Y_test)))\n",
    "for i in range(len(results)):\n",
    "    print('name:{}; score: {}'.format(results[i][0],results[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold 将数据分成10份，其中一份作为交叉验证数据集来计算模型准确性。\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 因为训练样本和测试样本是随机的，\n",
    "# 所以我们需要多次分配训练集和交叉验证数据集，然后对多次预测结果进行平均。\n",
    "results = []\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_result = cross_val_score(model,X,Y,cv=kfold)\n",
    "    results.append((name,cv_result))\n",
    "for i in range(len(results)):\n",
    "    print('name: {}; cross val score: {}'.format\n",
    "          (results[i][0],results[i][1].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
    "knn.fit(X_train,Y_train)\n",
    "train_score = knn.score(X_train,Y_train)\n",
    "test_score = knn.score(X_test,Y_test)\n",
    "print('train score: {} ; test score: {}'.format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = X_train\n",
    "y = Y_train\n",
    "#画出data在某模型上的learning curve.\n",
    "def plot_learning_curve(plt, estimator, title, X, y ,ylim=None, cv=None, n_jobs=1,\n",
    "                        train_sizes=np.linspace(.1,1.0,5)):\n",
    "#参数解释\n",
    "    #estimator : 你用的分类器。\n",
    "    #title : 表格的标题。\n",
    "    #x: 输入的feature，numpy类型\n",
    "    #y : 输入的target vector\n",
    "    #ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点\n",
    "    #cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，\n",
    "    #其余n-1份作为training(默认为3份)    \n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score')\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator,X,y,cv=cv,n_jobs=n_jobs,train_sizes=train_sizes\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes,train_scores_mean-train_scores_std,\n",
    "                    train_scores_mean + train_scores_std,alpha = 0.1, color='r')\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o--', color=\"r\",\n",
    "             label=\"Training score\") \n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "cv=ShuffleSplit(n_splits=10,test_size=0.2,random_state=0) # 打乱数据，取几折防止数据有序\n",
    "plt.figure(figsize=(10,6),dpi=64)\n",
    "plot_learning_curve(plt,knn,\"cure\",x,y,ylim=(0.0,1.01),cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***进一步练习写一个完整的糖尿病预测的 SVM的程序，包括前面的数据加载过程，并执行***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# 含有特征的数据集\n",
    "X = data.iloc[:,0:8]\n",
    "# 标记数据\n",
    "Y = data.iloc[:,8]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 将数据集划分为训练集和测试集，其中测试数据为20%\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3)  \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='scale')\n",
    "\n",
    "svc.fit(X_train,Y_train)\n",
    "train_score = svc.score(X_train,Y_train)\n",
    "test_score = svc.score(X_test,Y_test)\n",
    "print('train score: {} ; test score: {}'.format(train_score, test_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
