{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1神经传导的原理\n",
    "## 1. 神经传导的原理  \n",
    "神经传导的工作原理很复杂，这里我们只简单介绍其概念，如果2-1所示：  \n",
    "\n",
    "![title](images/2-1.png)  \n",
    "\n",
    "<center>图2-1</center>  \n",
    "\n",
    "- **轴突传送信息：**神经元长出一个细长条的轴突，以电流方式将信息传递给另一个神经元。轴突最长可达一米，最短只有几十分之一毫米。  \n",
    "- **树突接受信息：**树突的主要功能是接收其他神经元传来的电化学信息，在传递给本身的细胞。\n",
    "- **突触是输入与输出的神经元传递的机制：**输入与输出的神经元之间发展处的特殊结构称为突触，神经元通过释放化学物质来传递信息，当电压达到临界值时，就会通过轴突传送电脉冲动作电位至接受神经元。 \n",
    "\n",
    "## 2. 以数学公式仿真神经元的传导  \n",
    "  \n",
    "为了将神经元的传导用计算机来仿真，我们必须将神经元的传导以数学公式来表示。以图2-2来说明如何以数学公式模拟神经元的信息传导。 \n",
    "![title](images/2-2.1.png)   \n",
    "![title](images/2-2.png)  \n",
    "图2-2可以整理为以下公式：  \n",
    "$$y=activation\\quad function(x_1\\times w_1+x_2\\times w_2+x_3\\times w_3)$$  \n",
    "  \n",
    "详细说明如表2-1所示。  \n",
    "\n",
    "| 项目 | 说明 |  \n",
    "| -----|----- |  \n",
    "| 输入$x$ | $x$仿真输入神经元，接收外界传送信息，共有3个输入神经元：$x_1$、$x_2$、$x_3$ |  \n",
    "|接受$y$|模拟接受神经元，只有一个接受神经元：$y$|  \n",
    "|权重$w$（weight）|权重$w$模拟轴突，连接输入域接受神经元，负责传送信息，共有3个轴突：$w_2$、$w_2$、$w_3$|  \n",
    "|偏差值$b$|偏差值$b$仿真突触的结构，代表神经元倍激活的程度，偏差值越高，越容易被激活并传递信息。|  \n",
    "|激活函数|激活函数仿真神经传导的工作方式，当接受神经元接受刺激的总和：$x_1\\times w_1+x_2\\times w_2+x_3\\times w_3+b$经过激活函数的计算大于临界  值时，会传递至下一个神经元。|    \n",
    "\n",
    "## 3. 激活函数通常为非线性函数   \n",
    "\n",
    "以上激活函数可以仿真神经传导的工作方式将上一层神经元信息传递到下一层。激活函数通常为非线性函数，加入激活函数能让神经网络处理比较复杂的非线性问题。图2-3给出了线性函数与非线性函数的图像。  \n",
    "![title](images/2-3.png)     \n",
    "<center>2-3 线性函数与非线性函数的图像</center>    \n",
    "Keras与Tensorflow支持很多激活函数，不过在此我们介绍最常用的两种：Sigmoid和ReLU。  \n",
    "\n",
    "## 4.Sigmoid激活函数   \n",
    "  \n",
    "常用的激活Sigmoid的公式如下：  \n",
    "$$f(x)=\\frac{1}{e^{-x}+1} $$   \n",
    "Sigmoid激活函数的图像然后如图2-4所示。    \n",
    "![title](images/2-4.png)  \n",
    "  \n",
    "Sigmoid激活函数其实与人类感觉神经对信号的接受类似，例如，当接受神经元所接受刺激的总和：  \n",
    "  \n",
    "- **小于临界值时，会忽略此刺激** 当$x<-5$时，输出y接近0.  \n",
    "- **大于临界值时，开始接受神经刺激**当$x$范围在-5与5之间时，随之x数值增大，y的值也加大。  \n",
    "- **大于一定程度时，感觉会开始钝化**即使会受到更大的刺激，感觉仍维持不变，即当$x>5$时，$y$的数值趋紧与1。  \n",
    "\n",
    "## 5. ReLU激活函数  \n",
    "\n",
    "另一个很常见的激活函数ReLU的图像如图2-5所示。当接收神经元所接受刺激的总和：    \n",
    "![title](images/2-5.png)  \n",
    "- **小于临界值时，会忽略此刺激** 当$x<0$时，输出y接近0。   \n",
    "- **大于临界值时，开始接受神经刺激**当$x>0$时，y的值等于x。  \n",
    "\n",
    "\n",
    "# 2.2 以矩阵运算仿真神经网络   \n",
    "\n",
    "前面只是以数学运算模拟单个接受神经元，本节将介绍以矩阵模拟两个接收神经元。     \n",
    "\n",
    "## 1. 以矩阵运算仿真神经网络的信息传导  \n",
    "多个接收神经元的神经网络如图2-6所示：  \n",
    "![title](images/2-6.png)  \n",
    "<center>图2-6</center>  \n",
    "\n",
    "- **以数学公式模拟输出与接受神经元的工作方式：**    \n",
    "\n",
    "$$y_1=activation\\quad function(x_1\\times w_{11}+x_2\\times w_{12}+x_3\\times w_{33}+b_1)$$   \n",
    "$$y_2=activation\\quad function(x_1\\times w_{21}+x_2\\times w_{22}+x_3\\times w_{33}+b_2)$$  \n",
    "\n",
    "- **以上两个数学公式可以整合成一个矩阵运算公式：**  \n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "y_1 & y_2\n",
    "\\end{bmatrix}=activation\\begin{pmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2 & x_3\n",
    "\\end{bmatrix} & \\times \\begin{bmatrix}\n",
    " w_{11}& w_{12}\\\\ \n",
    " w_{21}& w_{22} \\\\\n",
    " w_{31}& w_{32}\n",
    "\\end{bmatrix}\n",
    "\\end{pmatrix}$$  \n",
    "- **另一种形式的矩阵公式表示如下：**   \n",
    "$$y=activation(x\\times w + b)$$   \n",
    "- **矩阵公式以中文标识如下： **       \n",
    "<center>输出=激活函数(输入$\\times$权重+偏差)</center>   \n",
    "\n",
    "详细说明如表2-2所示。  \n",
    "\n",
    "|项目|说明|  \n",
    "|-----|-----|  \n",
    "|输入$x$|$x$仿真输入神经元，接收外界传送信息，共有3个输入神经元：$x_1$、$x_2$、$x_3$|  \n",
    "|接受$y$|模拟接受神经元，只有一个接受神经元：$y_1$、$y_2$|\n",
    "|权重$w$（weight）|权重$w$模拟轴突，连接输入域接受神经元，负责传送信息，共有6个轴突：$w_11$、$w_21$、$w_31$、$w_12$、$w_22$、$w_32$|  \n",
    "|偏差值$b$|偏差值$b$仿真突触的结构，代表神经元倍激活的程度，偏差值越高，越容易被激活并传递信息。|  \n",
    "|激活函数|激活函数仿真神经传导的工作方式，当接受神经元接受刺激的总和：$x_1\\times w_11+x_2\\times w_21+x_3\\times w_31+b$经过激活函数的计算大于临界值时，会传递至下一个神经元。|  \n",
    "\n",
    "\n",
    "# 2.3 多层感知器模型  \n",
    "\n",
    "多层感知器模型(Multilayer Perceptron,MLP)是一种受欢迎的机器学习解决方案，尤其是在语音识别、图像识别和机器翻译等多个领域。到20世纪90年代，MLP遇到来自更简单的模型（例如，支持向量机）的强烈竞争。近年来，由于深度学习的成功，多层感知器又重新受到业界的重视。  \n",
    "  \n",
    "## 1.以多层感知器模型识别MINST手写数字图像  \n",
    "\n",
    "我们将以多层感知器模型识别MINIST手写数字图像说明多层感知器模型的工作方式，如图2-7所示。  \n",
    "![title](images/2-7.png)  \n",
    "<center>图2-7</center>  \n",
    "\n",
    "## 2.以矩阵公式仿真多层感知器模型的工作方式  \n",
    "\n",
    "![title](images/2-8.png)  \n",
    "\n",
    "- 建立输入层与隐藏层的公式：  \n",
    "<center>$h1=ReLU(x\\times w1+b1)$</center>  \n",
    "\n",
    "详细说明如表2-4所示。  \n",
    "\n",
    "|项目|说明|  \n",
    "|-----|-----|  \n",
    "|输入$x$|$x$仿真输入神经元，接收外界传送信息，如图2-7所示，共有784个神经元|    \n",
    "|隐藏层$h1$|隐藏层h1模拟内部神经元，共有256个隐藏神经元|  \n",
    "|权重$w1$（weight）|权重$w$模拟神经元的轴突，连接输入域接受神经元，负责传送信息。连接输入层（786个神经元）与隐藏层（256个神经元），为了让两层的每一个神经元都互相连接，总共需要$781\\times 256=200704$个轴突。所以$w1$必须是$784\\times 256$的矩阵，用来模拟这些轴突的功能|  \n",
    "|偏差值$b2$|偏差值$b2$仿真突触的结构，代表接受神经元倍激活的程度，偏差值越高，越容易被激活并传递信息。|  \n",
    "|激活函数|激活函数仿真神经传导的工作方式，在此我们使用ReLU激活函数接受刺激的总和：$(x\\times w1+b1)$,经过激活函数ReLU的运算，大于临界值时，会传递至下一个神经元。|  \n",
    "- 建立隐藏层与输出层的公式：  \n",
    "\n",
    "<center>$y=softmax(h1\\times w2+b2)$</center>  \n",
    "\n",
    "详细说明如表2-5所示。  \n",
    "\n",
    "|项目|说明|  \n",
    "|-----|-----|  \n",
    "|隐藏层$h1$|隐藏层$h1$模拟内部神经元，共有256个隐藏神经元|  \n",
    "|输出层$y$|模拟输出神经元，就是预测的结果，共有10个输出神经元。对应到我们希望预测的数字，从0到9共有10个输出结果|\n",
    "|权重$w2$（weight）|权重模拟神经元的轴突，连接输入与接收神经元，负责传送信息。|  \n",
    "|偏差值$b2$|偏差值$b2$仿真突触的结构，代表接受神经元倍激活的程度，偏差值越高，越容易被激活并传递信息。|   \n",
    "|激活函数|激活函数仿真神经传导的工作方式，在此我们使用ReLU激活函数接受刺激的总和：$(w2\\times h1+b2)$,经过softmax运算后的输出是一个概率分布，共有10个输出，数值越高代表概率越高，例如输出结果由0算起第7个数字最高，代表预测结果是7|  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print (\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
