{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>深度学习框架——小练习</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习1：多层神经网络的数据分类\n",
    "\n",
    "* 任务：生成虚拟数据，分成10类数据\n",
    "\n",
    "```py\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "```\n",
    "\n",
    "* 提示：标签需要转换为one-hot编码，keras.utils.to_categorical(labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小练习\n",
    "# 基于多层感知器的多分类\n",
    "# 提示：标签需要转换为one-hot编码，keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) 是一个具有 64 个隐藏神经元的全连接层。\n",
    "# 在第一层必须指定所期望的输入数据尺寸：\n",
    "# 在这里，是一个 20 维的向量。\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习2：多层神经网络的调参优化\n",
    "\n",
    "* 1.增加模型深度，改成2个隐藏层，model.add(Dense(500,activation='tanh'))\n",
    "* 2.更换损失函数，mse、categorical_crossentropy\n",
    "* 3.更换激活函数，sigmoid、softmax、relu、tanh\n",
    "* 4.更换优化器，SGD、Adam、RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小练习\n",
    "# 多层神经网络的调参优化\n",
    "# 1.增加模型深度，改成2个隐藏层，model.add(Dense(500,activation='tanh'))\n",
    "# 2.更换损失函数，mse、categorical_crossentropy\n",
    "# 3.更换激活函数，sigmoid、softmax、relu、tanh\n",
    "# 4.更换优化器，SGD、Adam、RMSprop\n",
    "\n",
    "# 加载模块\n",
    "import keras\n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# 准备数据\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "# 建立模型\n",
    "model = Sequential()\n",
    "model.add(Dense(500,activation='relu',input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=RMSprop(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(x_train,y_train,batch_size=128,epochs=2,verbose=1,\n",
    "         validation_data=(x_test,y_test))\n",
    "\n",
    "# 评估模型\n",
    "score = model.evaluate(x_test,y_test,verbose=1)\n",
    "print('Test loss:',score[0])\n",
    "print('Test accuracy',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3：卷积神经网络LeNet实践\n",
    "* 尝试用卷积神经网络LeNet实现MNIST识别分类，网络结构参考如下\n",
    "![](images/lianxi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "# 引入Tensorboard\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data() # out: np.ndarray\n",
    "x_train, y_train, x_test, y_test = x_train[:6000], y_train[:6000], x_test[:1000], y_test[:1000]\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Dense, Conv2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5),padding='valid',input_shape=(28, 28, 1), activation='tanh'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5),padding='valid', activation='tanh'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120, activation='tanh'))\n",
    "\n",
    "model.add(Dense(84, activation='tanh'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=2\n",
    "          ,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
